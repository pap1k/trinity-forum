from bs4 import BeautifulSoup as bs
import requests, re, time, datetime, xmltodict, vk, sys, html, antiddos
from logger import get_logger


logger = get_logger(__name__)

LASTID = 0
PROCESSING = {}
DELAY = 180

def date(unixtime, format = '%d.%m.%Y %H:%M:%S'):
    d = datetime.datetime.fromtimestamp(unixtime)
    return d.strftime(format)

def getAta4(subforums):
    for i in range(len(subforums)-1, 0, -1):
        title = subforums[i].lower()
        if "–∂–∞–ª–æ–±—ã –Ω–∞ —Ö–µ–ª–ø–µ—Ä–æ–≤" in title:
            return "ata4s/helper_report.jpg"
        elif "–ø—Ä–µ—Ç–µ–Ω–∑–∏–∏ –∫ —Ä–∞–±–æ—Ç–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤" in title:
            return "ata4s/admin_report.jpg"
        elif "–Ω–∞ –ª–∏–¥–µ—Ä–æ–≤ —Ñ—Ä–∞–∫—Ü–∏–π, –±–∞–Ω–¥," in title:
            return "ata4s/leader_report.jpg"
        elif "–Ω–æ–≤—ã–π –ª–∏–¥–µ—Ä" in title:
            return "ata4s/new_leader.jpg"
        elif "–±–∞–Ω–¥—ã" in title:
            return "ata4s/gang_news.jpg"
        elif "–±–∞–π–∫–µ—Ä—Å–∫–∏–µ –∫–ª—É–±—ã" in title:
            return "ata4s/biker_news.jpg"
        elif "–º–∞—Ñ–∏–∏" in title:
            return "ata4s/maf_news.jpg"
        elif "–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ" in title:
            return "ata4s/polit_news.jpg"
        elif "–ø–µ—Ä–µ–¥–∞—á—É –ø–æ—Å—Ç–æ–≤" in title:
            return None
        elif "–ø–æ–æ—â—Ä–µ–Ω–∏—è –ª–∏–¥–µ—Ä–∞–º" in title:
            return None
        elif "–≤—ã–≥–æ–≤–æ—Ä—ã –ª–∏–¥–µ—Ä–æ–≤" in title:
            return "ata4s/leader_reb.jpg"
    return "ata4s/fract_news.jpg"

class Forum:
    s = requests.Session()
    s.headers.update({'User-Agent': 'Grecko/1.0'})
    s.proxies = {'http': 'socks5h://127.0.0.1:9050','https': 'socks5h://127.0.0.1:9050'}
    def __init__(self):
        index = self.s.get('https://gta-trinity.ru/forum/').text
        logger.info('–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ.')
        #if "REACTLABSPROTECTION" in index:
        ddos_code = antiddos.get(index)
        logger.debug(f'ddos code: {ddos_code}')
        cookies = dict(
            name='REACTLABSPROTECTION',
            value=ddos_code,
            path='/',
            domain='gta-trinity.ru',
            expires=2145916555,
            rest = {'hostOnly':True}
        )
        logger.info('–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –æ–±—Ö–æ–¥. –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –ø–∞—Ä—Å–∏–Ω–≥.')
        self.s.cookies.set(**cookies)
    def html(self):
        return self.s.get("https://gta-trinity.ru:443/forum/index.php?/discover/8.xml/", timeout=20)

    def linkhtml(self, link):
        return self.s.get(link, timeout=20)
forum = Forum()
posted_ids = open("posts.txt", "r").read().split(",")
news_names = ['ny≈´su', 'novedad', 'NOTIZIA', 'ùêçùêûùê∞ùê¨', '–Ω–æ–≤–æ—Å—Ç', '–Ω—å—é—Å', 'notizie', 'news','noticias', '–Ω–æ–≤—ã–π –ª–∏–¥–µ—Ä', '–≤—ã–≥–æ–≤–æ—Ä—ã –ª–∏–¥–µ—Ä–æ–≤', '–∂–∞–ª–æ–±—ã –Ω–∞ —Ö–µ–ª–ø–µ—Ä–æ–≤', '–ø—Ä–µ—Ç–µ–Ω–∑–∏–∏ –∫ —Ä–∞–±–æ—Ç–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤', '–Ω–∞ –ª–∏–¥–µ—Ä–æ–≤ —Ñ—Ä–∞–∫—Ü–∏–π, –±–∞–Ω–¥,', '–ø–µ—Ä–µ–¥–∞—á—É –ø–æ—Å—Ç–æ–≤', '–ø–æ–æ—â—Ä–µ–Ω–∏—è –ª–∏–¥–µ—Ä–∞–º –∏ —Ö–µ–ª–ø–µ—Ä–∞–º']
news_alerts = ['usa na]', 'pa$e news', 'usa news', 'news agency', 'rc news', 'usa:news','af news', 'us news', 'rc:news', '–Ω–æ–≤–æ—Å—Ç–Ω–æ–µ']

while True:
    try:
        ghtml = forum.html()
        #print(ghtml.text)
        if not ghtml:
            logger.error(f'–§–æ—Ä—É–º —Å–¥–æ—Ö: {str(ghtml)}')
            continue
        try:
            xml = xmltodict.parse(ghtml.text, encoding='utf-8')
        except:
            logger.info(f'–ù–µ —É–¥–∞–ª–æ—Å—å —Å–ø–∞—Ä—Å–∏—Ç—å XML. –ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...')
            forum = Forum()
            continue
        for post in xml['rss']['channel']['item']:

            post_id = re.findall(r't&comment=(\d+)', post['link'])[0]
            title = post['title']
            #log(title)

            HasTitle=False
            ExitFlag=False
            for news_alert in news_alerts:
                if not ExitFlag:
                    sub = title.lower().replace(news_alert, '')
                    if len(sub) != len(title): ExitFlag = True
            for news_name in news_names:
                if news_name.lower() in sub:
                    HasTitle = True
            if(not HasTitle): continue

            if str(post_id) in posted_ids:
                continue

            posted_ids.append(post_id)
            PROCESSING = {"id": post_id, "title": title}
            LASTID = post_id
            if len(posted_ids) >= 20:
                posted_ids = posted_ids[1:]
            open("posts.txt", "w").write(",".join(posted_ids))
            #choosing hashtag
            if "–∂–∞–ª–æ–±" in title.lower() or "–ø—Ä–µ—Ç–µ–Ω–∑" in title.lower():
                tag = "#ccreport"
            else:
                tag = "#ccnews"

            attached_images = []
            index = bs(forum.linkhtml(post['link']).text,'html.parser')
            forum_post = index.find_all('div', class_='ipsColumn ipsColumn_fluid')[-1]
            forum_post = forum_post.find('div', class_='ipsType_normal ipsType_richText ipsContained')
            try:
                for img in forum_post.find_all('img'):
                    if not "emoji" in img['src']:
                        attached_images.append(img['src'])
            except: pass
            
            if len(attached_images) == 0:
                hat = None
                index = bs(forum.linkhtml(re.findall(r"(.+)\?do=findComment&", post['link'])[0]).text,'html.parser')

                forum_post = index.find_all('div', class_='ipsColumn ipsColumn_fluid')[0]
                forum_post = forum_post.find('div', class_='ipsType_normal ipsType_richText ipsContained')
                try: hat = forum_post.find_all('img')[0]['src']
                except: pass

            subforum = []
            nav_bar = index.find('nav', class_="ipsBreadcrumb ipsBreadcrumb_top ipsFaded_withHover")
            nav_bar = nav_bar.find('ul', attrs={"data-role": True})
            spans = nav_bar.find_all('span')
            for sp in spans:
                subforum.append(re.sub(r'(\<(/?[^>]+)>)', '', str(sp)))
            subforum.append(title)

            #sending post to vk
            #uploading photo(s)
            if len(attached_images) != 0:
                photo = ""
                for img in attached_images:
                    photo += vk.upload_photo(img) + ","
            elif hat:
                photo = vk.upload_photo(hat)
            else:
                photo = vk.upload_photo(getAta4(subforum))

            post['description'] = re.sub(r'\t', '', post['description'])
            post['description'] = re.sub(r'\n\s*\n', '\n', post['description'])
            post['description'] = html.unescape(post['description'])

            wall_post_data =  {
                    "owner_id": 0-vk.POST_GROUP_ID,
                    "from_group": 1,
                    "message": f"{tag}\n{title}\n\n{post['description']}",
                    "publish_date": int(time.time())+24*3600,
                    "copyright": post['link']
                }
            if photo: wall_post_data["attachments"] = photo,
            result = vk.vk_r("wall.post", wall_post_data)
            vk.vk_r("messages.send", {"peer_id": vk.PROD_CONV_PEER, "message": f"–í –æ—Ç–ª–æ–∂–∫–µ –Ω–æ–≤—ã–π –ø–æ—Å—Ç:\n\n{tag}\n{title}\n\n{post['link']}"})
            #vk.vk_r("messages.send", {"peer_id": 218999719, "message": f"–í –æ—Ç–ª–æ–∂–∫–µ –Ω–æ–≤—ã–π –ø–æ—Å—Ç:\n\n{tag}\n{title}\n\n{post['link']}"})
            
            dots = ':::::::::::::::::::::::::::::::::::::::'
            logger.info(f'\n{dots}\nPosted "{title}" post_id = "{str(post_id)}\n{dots}\n\n')
        time.sleep(DELAY)
    except KeyboardInterrupt:
        logger.debug(f'\n\n–í—ã—Ö–æ–¥–∏–º.')
        sys.exit(1)
    except requests.exceptions.RequestException as ex:
        if PROCESSING['id'] != LASTID:
            vk.vk_r("messages.send", {"peer_id": vk.PROD_CONV_PEER, "message": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –æ–±—Ä–∞—Ç–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞ {PROCESSING['id']} –≤ —Ç–µ–º–µ {PROCESSING['title']}, —Å–≤—è–∑–∞–Ω–Ω–∞—è —Å –æ—à–∏–±–∫–æ–π –ø–æ–¥–∫–æ–ª—á—é–µ–Ω–∏—è –∫ —Ñ–æ—Ä—É–º—É ({str(ex)}). –¥–µ—Ä–∂—É –≤ –∫—É—Ä—Å–µ."})
        logger.warning(f'Request error: {str(ex)}')
    # except Exception as ex:
    #     open("lastheml.html", "w", encoding='utf-8').write(ghtml.text)
    #     forum = Forum()
    #     log("–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ. –§–æ—Ä—É–º –æ–±–Ω–æ–≤–ª–µ–Ω."+str(ex))
